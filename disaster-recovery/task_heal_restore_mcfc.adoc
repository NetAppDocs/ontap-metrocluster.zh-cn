---
permalink: disaster-recovery/task_heal_restore_mcfc.html 
sidebar: sidebar 
keywords: configure, fc, switches, metrocluster, configuration 
summary: 更换硬件并分配磁盘后，您可以执行 MetroCluster 修复操作。 
---
= 执行聚合修复和还原镜像（ MetroCluster FC 配置）
:icons: font
:imagesdir: ../media/


[role="lead"]
更换硬件并分配磁盘后，您可以执行 MetroCluster 修复操作。然后，您必须确认聚合已镜像，并在必要时重新启动镜像。

.步骤
. 在灾难站点上执行两个修复阶段（聚合修复和根修复）：
+
[listing]
----
cluster_B::> metrocluster heal -phase aggregates

cluster_B::> metrocluster heal -phase root aggregates
----
. 监控修复过程，并验证聚合是否处于重新同步或镜像状态：
+
`storage aggregate show -node local`

+
|===


| 如果聚合显示此状态 ... | 那么 ... 


 a| 
正在重新同步
 a| 
无需执行任何操作。让聚合完成重新同步。



 a| 
镜像已降级
 a| 
继续执行 <<step3_fc_aggr_healing,第 3 步>>



 a| 
已镜像，正常
 a| 
无需执行任何操作。



 a| 
未知，脱机
 a| 
如果更换了灾难站点上的所有磁盘，则根聚合将显示此状态。

|===
+
[listing]
----
cluster_B::> storage aggregate show -node local

 Aggregate     Size Available Used% State   #Vols  Nodes      RAID Status
 --------- -------- --------- ----- ------- ------ ---------- ------------
 node_B_1_aggr1
            227.1GB   11.00GB   95% online       1 node_B_1   raid_dp,
                                                              resyncing
 NodeA_1_aggr2
            430.3GB   28.02GB   93% online       2 node_B_1   raid_dp,
                                                              mirror
                                                              degraded
 node_B_1_aggr3
            812.8GB   85.37GB   89% online       5 node_B_1   raid_dp,
                                                              mirrored,
                                                              normal
 3 entries were displayed.

cluster_B::>
----
+
在以下示例中，三个聚合各自处于不同的状态：

+
|===


| 节点 | 状态 


 a| 
node_B_1_aggr1
 a| 
正在重新同步



 a| 
node_B_1_aggr2
 a| 
镜像已降级



 a| 
node_B_1_aggr3.
 a| 
已镜像，正常

|===
. 【第 3 步 _fc_aggr_healing 】如果一个或多个丛保持脱机状态，则需要执行其他步骤来重建镜像。
+
在上表中，必须重建 node_B_1_aggr2 的镜像。

+
.. 查看聚合的详细信息以确定任何出现故障的丛：
+
`storage aggregate show -r -aggregate node_B_1_aggr2`

+
在以下示例中，丛 /node_B_1_aggr2/plex0 处于故障状态：

+
[listing]
----
cluster_B::> storage aggregate show -r -aggregate node_B_1_aggr2

 Owner Node: node_B_1
  Aggregate: node_B_1_aggr2 (online, raid_dp, mirror degraded) (block checksums)
   Plex: /node_B_1_aggr2/plex0 (offline, failed, inactive, pool0)
    RAID Group /node_B_1_aggr2/plex0/rg0 (partial)
                                                               Usable Physical
      Position Disk                     Pool Type     RPM     Size     Size Status
      -------- ------------------------ ---- ----- ------ -------- -------- ----------

   Plex: /node_B_1_aggr2/plex1 (online, normal, active, pool1)
    RAID Group /node_B_1_aggr2/plex1/rg0 (normal, block checksums)
                                                               Usable Physical
      Position Disk                     Pool Type     RPM     Size     Size Status
      -------- ------------------------ ---- ----- ------ -------- -------- ----------
      dparity  1.44.8                    1   SAS    15000  265.6GB  273.5GB (normal)
      parity   1.41.11                   1   SAS    15000  265.6GB  273.5GB (normal)
      data     1.42.8                    1   SAS    15000  265.6GB  273.5GB (normal)
      data     1.43.11                   1   SAS    15000  265.6GB  273.5GB (normal)
      data     1.44.9                    1   SAS    15000  265.6GB  273.5GB (normal)
      data     1.43.18                   1   SAS    15000  265.6GB  273.5GB (normal)
 6 entries were displayed.

 cluster_B::>
----
.. 删除故障丛：
+
`storage aggregate plex delete -aggregate aggregate-name -plex plex`

.. 重新建立镜像：
+
`storage aggregate mirror -aggregate aggregate-name`

.. 监控丛的重新同步和镜像状态，直到所有镜像均已重新建立且所有聚合均显示已镜像，正常状态：
+
`s存储聚合显示`




